# Pràctica Kaggle APC UAB 2022-23### Nom: Javier Esmoris Cerezuela### Dataset: kickstarter-projects### URL: [kaggle](https://www.kaggle.com/datasets/kemical/kickstarter-projects)## ResumEl dataset utilitza dades de Kickstarter, una plataforma de crowdfunding. Tenim dos datasets amb més de 300000 entrades amb 15 i 17 atributs. Un 40% d'ells és categòric, el 13% són dates i la resta són numèrics i no estan normalitzats. Farem servir el segon dataset ja que difereixen en alguns atributs i tenim dades de sobra.### Objectius del datasetVolem ser capaços de predir l'estat del projecte (e.g. failed, successful, live, canceled...) a partir de dades com les dates de llançament i venciment, la quantitat a acumular, el pais d'origen i altres més.## ExperimentsA continuació veurem els diferents experiments que hem fet.### PreprocessatPrimer s'ha fet una exploració de les dades per entendre cadascun dels atributs. En aquesta exploració s'han descartat diversos atributs que, o bé no aporten res al problema (ID del projecte i el seu nom), o bé són redundants (usd pledged, pledged, usd pledged real...).Una vegada s'han descartat aquests atributs processem els NaNs. Sorprenentment no hi ha cap i podem seguir endevant.Es defineixen dos nous atributs numèrics:- elapsed_days: dies que han passat- pledged/backer: mitja de donació per contribuïdorDesprés es treuen totes les entrades que en l'atribut a predir _state_ tenen un valor diferent de _succesful_ o _failed_ (i.e. _live_, _canceled_, _suspended_, _undefined_) per les poques entrades que tenien en comparació i per tenir un model més senzill, un classificador binari.També s'han filtrat _outliers_ de les variables numèriques i s'ha fet un recompte dels diferents valors que prenen les variables categòriques (alguna amb 159 valors diferents).Finalment s'han mirat les correlacions dels atributs numèrics i s'han normalitzat. Pels catègorics s'aplicarà _binary encoding_ i _one-hot-encoding_.### Model| Model | Hiperparametres | Mètrica | Temps || -- | -- | -- | -- || [Random Forest](link) | 100 Trees, XX | 57% | 100ms || Random Forest | 1000 Trees, XX | 58% | 1000ms || SVM | kernel: lineal C:10 | 58% | 200ms || -- | -- | -- | -- || [model de XXX](link al kaggle) | XXX | 58% | ?ms || [model de XXX](link al kaggle) | XXX | 62% | ?ms |## DemoPer tal de fer una prova, es pot fer servir amb la següent comanda``` python3 demo/demo.py --input here ```## ConclusionsEl millor model que s'ha aconseguit ha estat...En comparació amb l'estat de l'art i els altres treballs que hem analitzat....## Idees per treballar en un futurUn treball que no ha donat temps d'implementar i seria interessant és filtrar el dataset per subcategories i aplicar _One leave out_.També, segons la capacitat de càlcul, probar models SVC, ja que hi havia un gran nombre d'atributs i no ha sigut possible. ## LlicenciaEl projecte s’ha desenvolupat sota llicència GNU GPL